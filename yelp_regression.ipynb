{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34a3f39",
   "metadata": {},
   "source": [
    "# Step 1: Explore the Datasets\n",
    "# _______________________________________________________________\n",
    "\n",
    "1. `yelp_business.json`: establishment data regarding location and attributes for all business in the dataset.\n",
    "2. `yelp_review.json`: Yelp review metadata by business.\n",
    "3. `yelp_user.json`: user profile metadata by business.\n",
    "4. `yelp_checkin.json`: online checkin metadata by business.\n",
    "5. `yelp_tip.json:` tip metadata by business.\n",
    "6. `yelp_photo.json`: photo metadata by business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65b96110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec09d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all the data sets\n",
    "businesses_df = pd.read_json('datasets/yelp_regression_project/yelp_business.json', lines=True) #mutiple json objects in dataset\n",
    "reviews_df = pd.read_json('datasets/yelp_regression_project/yelp_review.json', lines=True)\n",
    "users_df = pd.read_json('datasets/yelp_regression_project/yelp_user.json', lines=True)\n",
    "checkins_df = pd.read_json('datasets/yelp_regression_project/yelp_checkin.json', lines=True)\n",
    "tips_df = pd.read_json('datasets/yelp_regression_project/yelp_tip.json', lines=True)\n",
    "photos_df = pd.read_json('datasets/yelp_regression_project/yelp_photo.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d825e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188593 entries, 0 to 188592\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   address             188593 non-null  object \n",
      " 1   alcohol?            188593 non-null  int64  \n",
      " 2   attributes          162807 non-null  object \n",
      " 3   business_id         188593 non-null  object \n",
      " 4   categories          188052 non-null  object \n",
      " 5   city                188593 non-null  object \n",
      " 6   good_for_kids       188593 non-null  int64  \n",
      " 7   has_bike_parking    188593 non-null  int64  \n",
      " 8   has_wifi            188593 non-null  int64  \n",
      " 9   hours               143791 non-null  object \n",
      " 10  is_open             188593 non-null  int64  \n",
      " 11  latitude            188587 non-null  float64\n",
      " 12  longitude           188587 non-null  float64\n",
      " 13  name                188593 non-null  object \n",
      " 14  neighborhood        188593 non-null  object \n",
      " 15  postal_code         188593 non-null  object \n",
      " 16  price_range         188593 non-null  int64  \n",
      " 17  review_count        188593 non-null  int64  \n",
      " 18  stars               188593 non-null  float64\n",
      " 19  state               188593 non-null  object \n",
      " 20  take_reservations   188593 non-null  int64  \n",
      " 21  takes_credit_cards  188593 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(10)\n",
      "memory usage: 31.7+ MB\n"
     ]
    }
   ],
   "source": [
    "businesses_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d831d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188593 entries, 0 to 188592\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   business_id               188593 non-null  object \n",
      " 1   average_review_age        188593 non-null  float64\n",
      " 2   average_review_length     188593 non-null  float64\n",
      " 3   average_review_sentiment  188593 non-null  float64\n",
      " 4   number_funny_votes        188593 non-null  int64  \n",
      " 5   number_cool_votes         188593 non-null  int64  \n",
      " 6   number_useful_votes       188593 non-null  int64  \n",
      "dtypes: float64(3), int64(3), object(1)\n",
      "memory usage: 10.1+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3585131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188593 entries, 0 to 188592\n",
      "Data columns (total 6 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   business_id                 188593 non-null  object \n",
      " 1   average_number_friends      188593 non-null  float64\n",
      " 2   average_days_on_yelp        188593 non-null  float64\n",
      " 3   average_number_fans         188593 non-null  float64\n",
      " 4   average_review_count        188593 non-null  float64\n",
      " 5   average_number_years_elite  188593 non-null  float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "users_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185e9e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 157075 entries, 0 to 157074\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   business_id       157075 non-null  object\n",
      " 1   time              157075 non-null  object\n",
      " 2   weekday_checkins  157075 non-null  int64 \n",
      " 3   weekend_checkins  157075 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "checkins_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e256ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121526 entries, 0 to 121525\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   business_id         121526 non-null  object \n",
      " 1   average_tip_length  121526 non-null  float64\n",
      " 2   number_tips         121526 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "tips_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3df87bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32976 entries, 0 to 32975\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   business_id             32976 non-null  object \n",
      " 1   average_caption_length  32976 non-null  float64\n",
      " 2   number_pics             32976 non-null  int64  \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 773.0+ KB\n"
     ]
    }
   ],
   "source": [
    "photos_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff601cf",
   "metadata": {},
   "source": [
    "# Step 1: Explore the Datasets â€“ Conclusion\n",
    "\n",
    "During the initial exploration of the datasets, several important findings were made:\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### 1. Shared `business_id` Column Across Datasets\n",
    "- A key relationship between datasets is the `business_id` column, which acts as a primary identifier. \n",
    "- This enables joining the datasets for deeper analysis and integrating information about businesses across multiple dimensions.\n",
    "\n",
    "### 2. Missing Data in Some Columns\n",
    "- Certain columns within the datasets have missing or null values.\n",
    "- This suggests the need for data cleaning or imputation to handle incomplete data effectively before performing any analysis.\n",
    "\n",
    "### 3. Data Types and Formats\n",
    "- The datasets contain a variety of data types, including strings, numbers, and categorical values. \n",
    "- Columns like `categories` or `attributes` may require further transformation or parsing due to their nested or string-encoded structures.\n",
    "\n",
    "### 4. Large File Sizes\n",
    "- The datasets are relatively large, indicating that memory optimization techniques, such as reading in chunks or working with a subset of data, might be necessary during analysis.\n",
    "\n",
    "\n",
    "### 5. Dataset-Specific Observations\n",
    "- **Business Dataset**: Contains essential details about businesses, including name, location, and category. Some businesses lack complete information on attributes like `hours` or `categories`.\n",
    "- **Review Dataset**: Contains user-generated content that can be analyzed for sentiment, trends, and customer feedback patterns. Text fields may need preprocessing.\n",
    "- **Check-in Dataset**: Provides insights into business foot traffic but may have sporadic or incomplete records.\n",
    "- **User Dataset**: Includes user information, useful for understanding reviewer demographics or loyalty trends.\n",
    "\n",
    "### 6. Preliminary Cleaning Needs\n",
    "- Handling missing values, inconsistent data types, and duplicate records will be a necessary step before conducting in-depth analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e330b",
   "metadata": {},
   "source": [
    "# Step 2: Merge the Datasets\n",
    "\n",
    "# __________________________________________________________________\n",
    "\n",
    "In this step I will merge the datasets into a single dataset. This will allow me to analyze the different features with respect to the target variable I am trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16312583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of Dataframes that need to be merged.\n",
    "df_list_to_merge = [businesses_df, reviews_df, users_df, checkins_df, tips_df, photos_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3eb7a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty Dataframe that will be used as the single DataFrame.\n",
    "yelp_df = pd.DataFrame()\n",
    "\n",
    "#For loop to merge each DataFrame within the df_list_to_merge\n",
    "for df in df_list_to_merge:\n",
    "    if yelp_df.empty:\n",
    "        yelp_df = df\n",
    "    else:\n",
    "        yelp_df = yelp_df.merge(right=df, how='outer', on='business_id', suffixes=('', '_dup')) # Suffixes checks for duplicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "510392b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 188593 entries, 0 to 188592\n",
      "Data columns (total 40 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   address                     188593 non-null  object \n",
      " 1   alcohol?                    188593 non-null  int64  \n",
      " 2   attributes                  162807 non-null  object \n",
      " 3   business_id                 188593 non-null  object \n",
      " 4   categories                  188052 non-null  object \n",
      " 5   city                        188593 non-null  object \n",
      " 6   good_for_kids               188593 non-null  int64  \n",
      " 7   has_bike_parking            188593 non-null  int64  \n",
      " 8   has_wifi                    188593 non-null  int64  \n",
      " 9   hours                       143791 non-null  object \n",
      " 10  is_open                     188593 non-null  int64  \n",
      " 11  latitude                    188587 non-null  float64\n",
      " 12  longitude                   188587 non-null  float64\n",
      " 13  name                        188593 non-null  object \n",
      " 14  neighborhood                188593 non-null  object \n",
      " 15  postal_code                 188593 non-null  object \n",
      " 16  price_range                 188593 non-null  int64  \n",
      " 17  review_count                188593 non-null  int64  \n",
      " 18  stars                       188593 non-null  float64\n",
      " 19  state                       188593 non-null  object \n",
      " 20  take_reservations           188593 non-null  int64  \n",
      " 21  takes_credit_cards          188593 non-null  int64  \n",
      " 22  average_review_age          188593 non-null  float64\n",
      " 23  average_review_length       188593 non-null  float64\n",
      " 24  average_review_sentiment    188593 non-null  float64\n",
      " 25  number_funny_votes          188593 non-null  int64  \n",
      " 26  number_cool_votes           188593 non-null  int64  \n",
      " 27  number_useful_votes         188593 non-null  int64  \n",
      " 28  average_number_friends      188593 non-null  float64\n",
      " 29  average_days_on_yelp        188593 non-null  float64\n",
      " 30  average_number_fans         188593 non-null  float64\n",
      " 31  average_review_count        188593 non-null  float64\n",
      " 32  average_number_years_elite  188593 non-null  float64\n",
      " 33  time                        157075 non-null  object \n",
      " 34  weekday_checkins            157075 non-null  float64\n",
      " 35  weekend_checkins            157075 non-null  float64\n",
      " 36  average_tip_length          121526 non-null  float64\n",
      " 37  number_tips                 121526 non-null  float64\n",
      " 38  average_caption_length      32976 non-null   float64\n",
      " 39  number_pics                 32976 non-null   float64\n",
      "dtypes: float64(17), int64(12), object(11)\n",
      "memory usage: 59.0+ MB\n"
     ]
    }
   ],
   "source": [
    "yelp_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b165e1",
   "metadata": {},
   "source": [
    "# Step 2: Merge the Datasets - Conclusion\n",
    "__________________________________________________________________\n",
    "\n",
    "To complete this step, I first created `df_list_to_merge`, a list object to hold all the datasets that needed to be merged. Next, I initialized `yelp_df` as an empty Pandas DataFrame to store the merged results.\n",
    "\n",
    "I then created a `for loop` that iterated through `df_list_to_merge` and merged `yelp_df` with each subsequent DataFrame in the list. Within the `merge` method, I used the following parameters:\n",
    "\n",
    "- **`right=df`**: This ensured that `yelp_df` was consistently merged with the next DataFrame in the list.\n",
    "- **`on='business_id'`**: This specified the `business_id` column as the primary key for the merge operation.\n",
    "- **`how='outer'`**: I chose an outer join to include all rows from each DataFrame, ensuring no data was lost even if there was no match on `business_id`.\n",
    "- **`suffixes=('', '_dup')`**: This allowed me to track potential duplicate columns created during the merge process.\n",
    "\n",
    "The final merged DataFrame, `yelp_df`, now contains 40 columns, representing the combination of information from all the original datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa463b37",
   "metadata": {},
   "source": [
    "# Step 3: Prepare and Clean the Data\n",
    "__________________________________________________________________\n",
    "\n",
    "In this step, I will prepare and clean the data for analysis and machine learning. The tasks include:\n",
    "\n",
    "- **Ensuring consistency in data formats**: \n",
    "  Standardizing the format of columns (e.g., date, numerical values, or categorical data).\n",
    "\n",
    "- **Handling missing values**: Addressing any `NaN` or null values by:\n",
    "  - Using the `.fillna()` method to replace `NaN` or missing values with `0`.\n",
    "  - Using the `.dropna()` method to drop rows or columns where values are missing or `NaN`.\n",
    "\n",
    "- **Removing irrelevant columns**: \n",
    "  Dropping columns that do not contribute to analysis or the training of the machine learning model using the `drop()` method.\n",
    "\n",
    "This step ensures that the dataset is clean, consistent, and ready for meaningful analysis and accurate machine learning predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d54b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082251c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
